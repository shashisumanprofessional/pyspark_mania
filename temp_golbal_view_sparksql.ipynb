{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deb7ec86-0a48-48f1-b3c3-4c77ed1af438",
   "metadata": {},
   "source": [
    "Here‚Äôs a **clear, practical explanation** of **Spark SQL**, **PySpark**, their **differences**, and **how they are related**, with examples.\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ What is Spark SQL?\n",
    "\n",
    "**Spark SQL** is a **module of Apache Spark** that lets you:\n",
    "\n",
    "* Run **SQL queries** on structured data\n",
    "* Work with **tables, views, and DataFrames**\n",
    "* Query data from **Hive, Parquet, ORC, JSON, CSV, JDBC**, etc.\n",
    "\n",
    "üëâ Spark SQL supports **ANSI-like SQL syntax**.\n",
    "\n",
    "### Example (Spark SQL)\n",
    "\n",
    "```sql\n",
    "SELECT dept, COUNT(*) \n",
    "FROM employees \n",
    "GROUP BY dept;\n",
    "```\n",
    "\n",
    "This SQL runs **inside Spark**, not a traditional database.\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ What is PySpark?\n",
    "\n",
    "**PySpark** is the **Python API for Apache Spark**.\n",
    "\n",
    "It allows you to:\n",
    "\n",
    "* Write Spark applications using **Python**\n",
    "* Work with **RDDs, DataFrames, Spark SQL**\n",
    "* Combine **Python logic + SQL queries**\n",
    "\n",
    "üëâ PySpark is how Python developers interact with Spark.\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ How Spark SQL and PySpark are Related\n",
    "\n",
    "Think of it like this:\n",
    "\n",
    "```\n",
    "Apache Spark (Engine)\n",
    " ‚îú‚îÄ‚îÄ Spark SQL (SQL processing engine)\n",
    " ‚îú‚îÄ‚îÄ PySpark (Python API)\n",
    " ‚îú‚îÄ‚îÄ Spark Core\n",
    " ‚îú‚îÄ‚îÄ MLlib\n",
    " ‚îî‚îÄ‚îÄ Spark Streaming\n",
    "```\n",
    "\n",
    "* **Spark SQL** = *What* you run (SQL queries)\n",
    "* **PySpark** = *How* you run it (Python interface)\n",
    "\n",
    "üëâ In PySpark, you can **execute Spark SQL queries**.\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Main Differences: Spark SQL vs PySpark\n",
    "\n",
    "| Feature               | Spark SQL             | PySpark                    |\n",
    "| --------------------- | --------------------- | -------------------------- |\n",
    "| Type                  | SQL engine/module     | Python API                 |\n",
    "| Language              | SQL                   | Python                     |\n",
    "| Use case              | Query structured data | Build Spark apps           |\n",
    "| Supports SQL          | ‚úÖ Yes                 | ‚úÖ Yes (via Spark SQL)      |\n",
    "| Supports Python logic | ‚ùå No                  | ‚úÖ Yes                      |\n",
    "| Best for              | Analysts, SQL users   | Data engineers, developers |\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Using SQL in PySpark (Very Common)\n",
    "\n",
    "### Step 1: Create DataFrame\n",
    "\n",
    "```python\n",
    "df = spark.read.csv(\"employees.csv\", header=True, inferSchema=True)\n",
    "```\n",
    "\n",
    "### Step 2: Create Temporary View\n",
    "\n",
    "```python\n",
    "df.createOrReplaceTempView(\"employees\")\n",
    "```\n",
    "\n",
    "### Step 3: Run Spark SQL\n",
    "\n",
    "```python\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT dept, AVG(salary) AS avg_salary\n",
    "    FROM employees\n",
    "    GROUP BY dept\n",
    "\"\"\")\n",
    "```\n",
    "\n",
    "### Step 4: Show Output\n",
    "\n",
    "```python\n",
    "result.show()\n",
    "```\n",
    "\n",
    "‚û°Ô∏è SQL is executed by **Spark SQL engine**, called **from PySpark**.\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ Spark SQL vs PySpark DataFrame API\n",
    "\n",
    "### Spark SQL\n",
    "\n",
    "```sql\n",
    "SELECT name FROM employees WHERE salary > 50000;\n",
    "```\n",
    "\n",
    "### PySpark DataFrame API (Same logic)\n",
    "\n",
    "```python\n",
    "df.filter(df.salary > 50000).select(\"name\")\n",
    "```\n",
    "\n",
    "üëâ Both compile into the **same execution plan** (Catalyst Optimizer).\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ Performance Difference?\n",
    "\n",
    "‚ùå **No performance difference**\n",
    "\n",
    "Why?\n",
    "\n",
    "* Both SQL and PySpark DataFrame API are optimized by **Catalyst Optimizer**\n",
    "* Both generate the **same Spark execution plan**\n",
    "\n",
    "‚ö†Ô∏è Performance issues arise only when:\n",
    "\n",
    "* Using Python UDFs\n",
    "* Converting DataFrames to Pandas\n",
    "\n",
    "---\n",
    "\n",
    "## 8Ô∏è‚É£ When to Use What?\n",
    "\n",
    "### Use Spark SQL when:\n",
    "\n",
    "* You are comfortable with SQL\n",
    "* Writing ad-hoc analytics queries\n",
    "* Working with BI tools (Hive, Presto-like)\n",
    "\n",
    "### Use PySpark when:\n",
    "\n",
    "* You need **complex logic**\n",
    "* Looping, branching, functions\n",
    "* ML pipelines or ETL jobs\n",
    "\n",
    "### Best Practice ‚úÖ\n",
    "\n",
    "üëâ **Use PySpark DataFrame API + Spark SQL together**\n",
    "\n",
    "---\n",
    "\n",
    "## 9Ô∏è‚É£ One-Line Summary\n",
    "\n",
    "> **Spark SQL is the SQL engine inside Spark, and PySpark is the Python interface that lets you use Spark SQL and other Spark features.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77965576-af34-4c2d-9239-24c89cfb2a59",
   "metadata": {},
   "source": [
    "Here‚Äôs a **clear, interview-ready explanation** of **Temporary Views vs Global Temporary Views** in **Spark SQL**, with examples and when to use each.\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Temporary View (Local Temp View)\n",
    "\n",
    "### üîπ What it is\n",
    "\n",
    "* A **session-scoped** view\n",
    "* Exists **only within the current SparkSession**\n",
    "* Automatically **deleted when the session ends**\n",
    "\n",
    "### üîπ Key Characteristics\n",
    "\n",
    "* Visible **only to the current session**\n",
    "* Not accessible from another SparkSession\n",
    "* Stored in **memory**, not persisted\n",
    "\n",
    "### üîπ Create Temp View\n",
    "\n",
    "```python\n",
    "df.createOrReplaceTempView(\"employees\")\n",
    "```\n",
    "\n",
    "### üîπ Query Temp View\n",
    "\n",
    "```sql\n",
    "SELECT * FROM employees;\n",
    "```\n",
    "\n",
    "### üîπ Lifetime\n",
    "\n",
    "* Ends when **SparkSession stops**\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Global Temporary View\n",
    "\n",
    "### üîπ What it is\n",
    "\n",
    "* An **application-scoped** view\n",
    "* Accessible across **multiple SparkSessions**\n",
    "* Stored in a special database: **`global_temp`**\n",
    "* Dropped only when **Spark application ends**\n",
    "\n",
    "### üîπ Key Characteristics\n",
    "\n",
    "* Shared across all sessions in the same Spark application\n",
    "* Must be referenced using `global_temp.view_name`\n",
    "* Not tied to a single session\n",
    "\n",
    "### üîπ Create Global Temp View\n",
    "\n",
    "```python\n",
    "df.createOrReplaceGlobalTempView(\"employees\")\n",
    "```\n",
    "\n",
    "### üîπ Query Global Temp View\n",
    "\n",
    "```sql\n",
    "SELECT * FROM global_temp.employees;\n",
    "```\n",
    "\n",
    "### üîπ Lifetime\n",
    "\n",
    "* Ends when **Spark application stops**\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Main Differences (Side-by-Side)\n",
    "\n",
    "| Feature       | Temp View        | Global Temp View        |\n",
    "| ------------- | ---------------- | ----------------------- |\n",
    "| Scope         | SparkSession     | Spark Application       |\n",
    "| Visible to    | One session only | All sessions            |\n",
    "| Database      | Default session  | `global_temp`           |\n",
    "| Access syntax | `view_name`      | `global_temp.view_name` |\n",
    "| Lifetime      | Session ends     | Application ends        |\n",
    "| Sharing data  | ‚ùå No             | ‚úÖ Yes                   |\n",
    "\n",
    "---\n",
    "\n",
    "## 4Ô∏è‚É£ Example Scenario\n",
    "\n",
    "### üîπ Temp View Use Case\n",
    "\n",
    "You‚Äôre running a **single ETL job**:\n",
    "\n",
    "```python\n",
    "spark.read.csv(\"sales.csv\").createOrReplaceTempView(\"sales\")\n",
    "```\n",
    "\n",
    "Used only in that script ‚Üí **Temp View is enough**\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ Global Temp View Use Case\n",
    "\n",
    "You have:\n",
    "\n",
    "* Multiple SparkSessions\n",
    "* Shared lookup or reference data\n",
    "\n",
    "```python\n",
    "df.createOrReplaceGlobalTempView(\"countries\")\n",
    "```\n",
    "\n",
    "Access from another session:\n",
    "\n",
    "```python\n",
    "spark2.sql(\"SELECT * FROM global_temp.countries\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5Ô∏è‚É£ Common Interview Questions\n",
    "\n",
    "### ‚ùì Can temp views be accessed across notebooks?\n",
    "\n",
    "* ‚ùå Temp View ‚Üí No\n",
    "* ‚úÖ Global Temp View ‚Üí Yes (within same Spark application)\n",
    "\n",
    "### ‚ùì Are they stored on disk?\n",
    "\n",
    "* ‚ùå No, both are logical views (metadata only)\n",
    "\n",
    "### ‚ùì Can they replace Hive tables?\n",
    "\n",
    "* ‚ùå No, they are temporary and not persisted\n",
    "\n",
    "---\n",
    "\n",
    "## 6Ô∏è‚É£ Best Practices ‚úÖ\n",
    "\n",
    "* Use **Temp View** for **single-job transformations**\n",
    "* Use **Global Temp View** for **shared reference data**\n",
    "* Use **Hive tables** for **persistent storage**\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ One-Line Summary\n",
    "\n",
    "> **Temp Views are session-specific, Global Temp Views are application-wide and shared across sessions.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ae376b-44d3-4799-9d89-c844fd261c08",
   "metadata": {},
   "source": [
    "Good question ‚Äî this is where **views vs tables and Spark security** really matter.\n",
    "\n",
    "Short answer first:\n",
    "\n",
    "> **Temp views and Global temp views are NOT meant for multi-user access.**\n",
    "> For multiple people, you must use **persistent tables + access control**.\n",
    "\n",
    "Now let‚Äôs break it down clearly.\n",
    "\n",
    "---\n",
    "\n",
    "## 1Ô∏è‚É£ Can multiple people access Temp Views?\n",
    "\n",
    "‚ùå **NO**\n",
    "\n",
    "### Why?\n",
    "\n",
    "* Temp views are **session-scoped**\n",
    "* Each user has their **own SparkSession**\n",
    "* When User A creates a temp view, User B **cannot see it**\n",
    "\n",
    "üëâ Even on Databricks:\n",
    "\n",
    "* Different users = different sessions\n",
    "* Temp views are **private**\n",
    "\n",
    "---\n",
    "\n",
    "## 2Ô∏è‚É£ Can multiple people access Global Temp Views?\n",
    "\n",
    "‚ö†Ô∏è **Technically possible, but NOT recommended**\n",
    "\n",
    "### When it works\n",
    "\n",
    "* Users share the **same Spark application**\n",
    "* Example: same Databricks cluster + same running app\n",
    "\n",
    "### Why it‚Äôs risky\n",
    "\n",
    "* Global temp views:\n",
    "\n",
    "  * Are **in-memory**\n",
    "  * Disappear when the app/cluster restarts\n",
    "  * Have **no security or permissions**\n",
    "* Any user can overwrite them\n",
    "\n",
    "```python\n",
    "df.createOrReplaceGlobalTempView(\"sales\")  # Anyone can replace it\n",
    "```\n",
    "\n",
    "üö´ Not suitable for production or true multi-user environments.\n",
    "\n",
    "---\n",
    "\n",
    "## 3Ô∏è‚É£ Correct Way: Use Tables (Best Practice) ‚úÖ\n",
    "\n",
    "## 6Ô∏è‚É£ What NOT to Do üö´\n",
    "\n",
    "| Bad Practice                 | Reason         |\n",
    "| ---------------------------- | -------------- |\n",
    "| Using temp views for sharing | Session-scoped |\n",
    "| Using global temp views      | No security    |\n",
    "| Sharing via memory           | Data loss      |\n",
    "| Relying on cluster lifetime  | Unreliable     |\n",
    "\n",
    "---\n",
    "\n",
    "## 7Ô∏è‚É£ Real-World Architecture (Recommended)\n",
    "\n",
    "```\n",
    "Raw Data (S3 / ADLS / HDFS)\n",
    "        ‚Üì\n",
    "Managed Tables (Bronze / Silver / Gold)\n",
    "        ‚Üì\n",
    "SQL Views\n",
    "        ‚Üì\n",
    "Users / BI Tools / Analysts\n",
    "```\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02a41a6-47b3-46b4-a242-2c40121baba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
