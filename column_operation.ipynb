{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f22c714d-1e1b-490d-bfed-2ec6efa4ab15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/15 16:18:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "26/01/15 16:18:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+----------+------+-------------+\n",
      "|id |name   |dept|join_date |salary|skills       |\n",
      "+---+-------+----+----------+------+-------------+\n",
      "|1  |Alice  |HR  |2024-01-10|NULL  |[Python, SQL]|\n",
      "|2  |Bob    |NULL|2024-02-15|5000  |[Java]       |\n",
      "|3  |Charlie|IT  |NULL      |7000  |NULL         |\n",
      "+---+-------+----+----------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "data = [\n",
    "    (1, \"Alice\", \"HR\", \"2024-01-10\", None, [\"Python\", \"SQL\"]),\n",
    "    (2, \"Bob\", None, \"2024-02-15\", 5000, [\"Java\"]),\n",
    "    (3, \"Charlie\", \"IT\", None, 7000, None)\n",
    "]\n",
    "\n",
    "columns = [\"id\", \"name\", \"dept\", \"join_date\", \"salary\", \"skills\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a937d1-4ecb-4979-979d-6e7091084932",
   "metadata": {},
   "source": [
    "select\n",
    "\n",
    "\n",
    "Used to pick specific columns from a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "447d1d6f-182e-4342-a9a0-f6435fab1dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|   name|dept|\n",
      "+-------+----+\n",
      "|  Alice|  HR|\n",
      "|    Bob|NULL|\n",
      "|Charlie|  IT|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"name\", \"dept\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70752998-dc5f-4edb-b586-0cc94aa1bc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+----------+------+-------------+\n",
      "| id|   name|dept| join_date|salary|       skills|\n",
      "+---+-------+----+----------+------+-------------+\n",
      "|  1|  Alice|  HR|2024-01-10|  NULL|[Python, SQL]|\n",
      "|  2|    Bob|NULL|2024-02-15|  5000|       [Java]|\n",
      "|  3|Charlie|  IT|      NULL|  7000|         NULL|\n",
      "+---+-------+----+----------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"*\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a1341d8-37b5-4bb8-a0a4-e7a756fdbbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+----------+------+-------------+\n",
      "| id|   name|dept| join_date|salary|       skills|\n",
      "+---+-------+----+----------+------+-------------+\n",
      "|  1|  Alice|  HR|2024-01-10|  NULL|[Python, SQL]|\n",
      "|  2|    Bob|NULL|2024-02-15|  5000|       [Java]|\n",
      "|  3|Charlie|  IT|      NULL|  7000|         NULL|\n",
      "+---+-------+----+----------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6202556-3cff-4be4-8943-2d5cf01dc946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+----------+------+-------------+\n",
      "| id|   name|dept| join_date|salary|       skills|\n",
      "+---+-------+----+----------+------+-------------+\n",
      "|  1|  Alice|  HR|2024-01-10|  NULL|[Python, SQL]|\n",
      "|  2|    Bob|NULL|2024-02-15|  5000|       [Java]|\n",
      "|  3|Charlie|  IT|      NULL|  7000|         NULL|\n",
      "+---+-------+----+----------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.columns).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fb7c0d-76c8-45ae-bd11-75fa17b9534e",
   "metadata": {},
   "source": [
    "withColumn\n",
    "\n",
    "\n",
    "Used to add a new column or modify an existing column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fd0fb44-67f4-4db4-8101-67747dce26e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+----------+------+-------------+------------+\n",
      "| id|   name|dept| join_date|salary|       skills|salary_bonus|\n",
      "+---+-------+----+----------+------+-------------+------------+\n",
      "|  1|  Alice|  HR|2024-01-10|  NULL|[Python, SQL]|        NULL|\n",
      "|  2|    Bob|NULL|2024-02-15|  5000|       [Java]|        6000|\n",
      "|  3|Charlie|  IT|      NULL|  7000|         NULL|        8000|\n",
      "+---+-------+----+----------+------+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"salary_bonus\",col(\"salary\")+1000).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea8baa9-a1ae-4eb3-b6ff-050b0d8d5d59",
   "metadata": {},
   "source": [
    "drop\n",
    "\n",
    "Used to remove a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c686d68-ac81-4eb7-812c-a185562ba698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+----------+------+\n",
      "| id|   name|dept| join_date|salary|\n",
      "+---+-------+----+----------+------+\n",
      "|  1|  Alice|  HR|2024-01-10|  NULL|\n",
      "|  2|    Bob|NULL|2024-02-15|  5000|\n",
      "|  3|Charlie|  IT|      NULL|  7000|\n",
      "+---+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.drop(\"skills\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a483850c-3d62-46b8-89c6-615269db47eb",
   "metadata": {},
   "source": [
    "alias\n",
    "\n",
    "\n",
    "Used to rename a column temporarily (mostly in select)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3930e172-7d8b-4979-8232-10123eb13e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|employee_name|\n",
      "+-------------+\n",
      "|        Alice|\n",
      "|          Bob|\n",
      "|      Charlie|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"name\").alias(\"employee_name\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6024de56-5f34-460c-8258-28e56f3aa3dd",
   "metadata": {},
   "source": [
    "cast\n",
    "\n",
    "\n",
    "Used to change the data type of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbe31407-d795-4ad4-a307-d6cbc63f96f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+----------+------+-------------+----------+\n",
      "| id|   name|dept| join_date|salary|       skills|Salary_int|\n",
      "+---+-------+----+----------+------+-------------+----------+\n",
      "|  1|  Alice|  HR|2024-01-10|  NULL|[Python, SQL]|      NULL|\n",
      "|  2|    Bob|NULL|2024-02-15|  5000|       [Java]|      5000|\n",
      "|  3|Charlie|  IT|      NULL|  7000|         NULL|      7000|\n",
      "+---+-------+----+----------+------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Salary_int\",col(\"salary\").cast(\"int\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceb935-67f0-4215-96ab-ca55ad0925bc",
   "metadata": {},
   "source": [
    "when (Conditional Logic)\n",
    "\n",
    "\n",
    "Works like IFâ€“ELSE condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b834de9-8a35-4f88-905c-bbb9d2906052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+----------+------+-------------+------------+\n",
      "| id|   name|dept| join_date|salary|       skills|salary_level|\n",
      "+---+-------+----+----------+------+-------------+------------+\n",
      "|  1|  Alice|  HR|2024-01-10|  NULL|[Python, SQL]|     Unknown|\n",
      "|  2|    Bob|NULL|2024-02-15|  5000|       [Java]|      Medium|\n",
      "|  3|Charlie|  IT|      NULL|  7000|         NULL|        high|\n",
      "+---+-------+----+----------+------+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\n",
    "    \"salary_level\",\n",
    "    when(col(\"salary\")>6000, \"high\")\n",
    "    .when(col(\"salary\")<=6000, \"Medium\")\n",
    "    .otherwise(\"Unknown\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7649bf92-cc63-4b9b-b44e-143d3d9e6a39",
   "metadata": {},
   "source": [
    "explode\n",
    "\n",
    "Used to break array values into multiple rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "395209b9-2ad3-4a8e-8d00-4f80d7eba51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "| name| skill|\n",
      "+-----+------+\n",
      "|Alice|Python|\n",
      "|Alice|   SQL|\n",
      "|  Bob|  Java|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"name\", explode(\"skills\").alias(\"skill\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7d579d-d52b-4bd6-870d-68aacf578154",
   "metadata": {},
   "source": [
    "coalesce\n",
    "\n",
    "\n",
    "Used to replace NULL values with another value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2b59bdc-ce3e-4e40-a19b-7c8f372c4994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+----------+------+-------------+\n",
      "| id|   name|dept| join_date|salary|       skills|\n",
      "+---+-------+----+----------+------+-------------+\n",
      "|  1|  Alice|  HR|2024-01-10|  NULL|[Python, SQL]|\n",
      "|  2|    Bob|NULL|2024-02-15|  5000|       [Java]|\n",
      "|  3|Charlie|  IT|      NULL|  7000|         NULL|\n",
      "+---+-------+----+----------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d711f30e-19ea-4f36-8e63-4cfcdd0e6362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+----------+-------+-------------+\n",
      "| id|   name|dept| join_date| salary|       skills|\n",
      "+---+-------+----+----------+-------+-------------+\n",
      "|  1|  Alice|  HR|2024-01-10|Unknown|[Python, SQL]|\n",
      "|  2|    Bob|NULL|2024-02-15|   5000|       [Java]|\n",
      "|  3|Charlie|  IT|      NULL|   7000|         NULL|\n",
      "+---+-------+----+----------+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"salary\",coalesce(col(\"salary\"),lit(\"Unknown\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27543b74-9e6d-45c1-9705-6f509cd2bf7a",
   "metadata": {},
   "source": [
    "Date Functions\n",
    "\n",
    "Common date functions in PySpark:\n",
    "\n",
    "Convert string â†’ date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5c75be5-a03d-4c48-a88f-958a1f546c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- dept: string (nullable = true)\n",
      " |-- join_date: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- skills: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bd19977-b712-407c-b600-a12968dcabdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+----------+------+-------------+\n",
      "| id|   name|dept| join_date|salary|       skills|\n",
      "+---+-------+----+----------+------+-------------+\n",
      "|  1|  Alice|  HR|2024-01-10|  NULL|[Python, SQL]|\n",
      "|  2|    Bob|NULL|2024-02-15|  5000|       [Java]|\n",
      "|  3|Charlie|  IT|      NULL|  7000|         NULL|\n",
      "+---+-------+----+----------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"join_date\",to_date(\"join_date\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa3132c4-181b-40d5-af9c-a99debd5e96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- dept: string (nullable = true)\n",
      " |-- join_date: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- skills: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2cbc01-9b2a-45ec-9d3e-9797d7d7c62c",
   "metadata": {},
   "source": [
    "## ðŸ”´ Why `join_date` is STILL `string` after `withColumn(...)`?\n",
    "\n",
    "### Your code:\n",
    "\n",
    "```python\n",
    "df.withColumn(\"join_date\", to_date(\"join_date\")).show()\n",
    "df.printSchema()\n",
    "```\n",
    "\n",
    "### â— Key Reason\n",
    "\n",
    "ðŸ‘‰ **PySpark DataFrames are IMMUTABLE**\n",
    "\n",
    "That means:\n",
    "\n",
    "> Any transformation (`withColumn`, `select`, `drop`, etc.)\n",
    "> **does NOT change `df` unless you assign it back**\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  What actually happened?\n",
    "\n",
    "```python\n",
    "df.withColumn(\"join_date\", to_date(\"join_date\")).show()\n",
    "```\n",
    "\n",
    "âœ”ï¸ Spark created a **new temporary DataFrame**\n",
    "âœ”ï¸ Converted `join_date` to `date`\n",
    "âœ”ï¸ Displayed it using `show()`\n",
    "âŒ **Original `df` was NOT modified**\n",
    "\n",
    "So when you run:\n",
    "\n",
    "```python\n",
    "df.printSchema()\n",
    "```\n",
    "\n",
    "You are still checking the **old DataFrame**, where `join_date` is a string.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Correct Way (Fix)\n",
    "\n",
    "You must **reassign** the DataFrame:\n",
    "\n",
    "```python\n",
    "df = df.withColumn(\"join_date\", to_date(\"join_date\"))\n",
    "df.printSchema()\n",
    "```\n",
    "\n",
    "### âœ… Output will now be:\n",
    "\n",
    "```\n",
    " |-- join_date: date (nullable = true)\n",
    "```\n",
    "\n",
    "âœ”ï¸ Now the column is truly converted.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§ª Proof Example\n",
    "\n",
    "### âŒ Without reassignment\n",
    "\n",
    "```python\n",
    "df.withColumn(\"join_date\", to_date(\"join_date\")).show()\n",
    "df.printSchema()   # still string\n",
    "```\n",
    "\n",
    "### âœ… With reassignment\n",
    "\n",
    "```python\n",
    "df = df.withColumn(\"join_date\", to_date(\"join_date\"))\n",
    "df.printSchema()   # date\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ Why PySpark works this way?\n",
    "\n",
    "* DataFrames are **immutable** (like SQL tables)\n",
    "* Prevents accidental data corruption\n",
    "* Improves performance & fault tolerance\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“ Rule to Remember (Interview Gold â­)\n",
    "\n",
    "> **In PySpark, every transformation returns a new DataFrame.\n",
    "> If you donâ€™t assign it, the change is lost.**\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Œ Quick Tip\n",
    "\n",
    "Same rule applies to:\n",
    "\n",
    "* `drop()`\n",
    "* `select()`\n",
    "* `withColumnRenamed()`\n",
    "* `filter()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "785dcb08-2a32-4b10-a3b6-f61b29018c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+----------+------+-------------+\n",
      "| id|   name|dept| join_date|salary|       skills|\n",
      "+---+-------+----+----------+------+-------------+\n",
      "|  1|  Alice|  HR|2024-01-10|  NULL|[Python, SQL]|\n",
      "|  2|    Bob|NULL|2024-02-15|  5000|       [Java]|\n",
      "|  3|Charlie|  IT|      NULL|  7000|         NULL|\n",
      "+---+-------+----+----------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1= df.withColumn(\"join_date\",to_date(\"join_date\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c03a4cf6-b881-44f6-8e41-af3d2fa77c5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'printSchema'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprintSchema\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'printSchema'"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0cd1fc-2644-494d-9574-63ce91330dba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
